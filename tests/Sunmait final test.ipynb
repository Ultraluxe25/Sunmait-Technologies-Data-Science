{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efeccd7b-704d-4337-83c4-40381b485768",
   "metadata": {},
   "source": [
    "### 1. Как работает расщепление на основе энтропии в решающих деревьях?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ff02b-7806-4e07-9690-3ea21f56cc4b",
   "metadata": {},
   "source": [
    "В решающем дереве есть три критерия разделения (по крайней мере в Scikit-Learn) - Джини, энтропия и лог лосс. Энтропия - это мера хаоса и неопределенности. Соответственно каждый сплит дерева должен в своих поддеревьях эту меру уменьшать, делая данные более предсказуемыми. Расщепление будет происходить по тому признаку, который имеет наивысший Information gain - разница значения энтропии до разделения и после."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790a38b-97dd-4aec-b724-76457284520d",
   "metadata": {},
   "source": [
    "### 2. Опишите как работает метод опорных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8636031-c156-4c6b-a7f4-8239a16142a0",
   "metadata": {},
   "source": [
    "SVM (В Scikit-Learn SVC) использует гиперплоскость для разделения признакового пространства на два подпространства (чаще для задач бинарной классификации используется, но можно и для регрессии). Цель метода в максимизации отступа разделяющей гиперплоскости от ближайших объектов обоих классов (опорных векторов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9b4ae-0eb8-4f20-8f3b-8d0f7a15482e",
   "metadata": {},
   "source": [
    "### 3. Для чего нужны ядерные (kernel) функции в SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aed7a0-d547-4bf5-a183-3bfaef67130e",
   "metadata": {},
   "source": [
    "Если признаковое пространство большое, то линейной гиперплоскостью их описать не получится (можем столкнуться с проблемой недообучения). Поэтому приходится пользоваться полиномами, которые позволяют описать нелинейные зависимости в данных, увеличив margin. Ядерные функции (линейная, полиномиальная и др.) помогают в этом, но могут и привести к проблеме высокой размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433c3ae-d8df-40ac-8048-791cb1aaa121",
   "metadata": {},
   "source": [
    "### 4. Для чего нужен параметр k в  kNN алгоритме?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2b3dd-7893-4567-907b-91cb319a6f65",
   "metadata": {},
   "source": [
    "k - это гиперпараметр, который отвечает за количество ближайших объектов (\"соседей\"), расстояние до которых будет вычислено до принятия решений (голосование большинством или усреднение). Маленькое значение k ведет к переобучению, а большое к недообучению, поэтому настраиваем с помощью Optuna тщательно. Метрики расстояния могут быть: Евклидова, Манхэттенская, косинусная, Махаланобиса, Миньковского (default=’minkowski’ в Scikit-Learn) и др. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbca70-c891-4076-8ad0-e692da821e46",
   "metadata": {},
   "source": [
    "### 5. Назовите три основных строительных блока алгоритмов обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5570e1-5809-447e-803f-3c5cc8644975",
   "metadata": {},
   "source": [
    "1) Подготовка данных (предобработка датасета, его подбор, а также EDA)\n",
    "2) Выбор алгоритма обучения (или группы), для решения задачи, правильную функции потерь и оптимизатор для конкретного типа задач\n",
    "3) Обучение модели, подбор гиперпараметров с помощью кросс-валидации и её тестирование на реальных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82a007-bde5-4f35-b231-73cce25ac298",
   "metadata": {},
   "source": [
    "### 6. Как инициализация параметров может повлиять на решение, найденное градиентным спуском в сложных моделях, таких как нейронные сети?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c15d68-6141-468b-8160-7c84cc5d09a5",
   "metadata": {},
   "source": [
    "При малых значениях весов градиент (вектор наискорейшего роста, а антиградиент скорейшего спуска, нам нужен антиградиент для минимизации функции потерь) может затухнуть и веса почти прекратят обновляться, а при больших значениях произойдет взрыв градиента. Для решения этих проблем существуют подходы для инициализации вроде Xavier (Glorot) или He."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc21b2-054e-4178-9bfa-a3be3e173d9a",
   "metadata": {},
   "source": [
    "### 7. Что такое проектирование признаков?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd42803b-3c46-4f8b-9fdb-2762262544d0",
   "metadata": {},
   "source": [
    "Feature Engineering - это создание новых признаков на основе имеющихся, используется в классическом машинном обучении, т.к. в глубоком обучение этим занимается не инженер, а нейронные сети. Чаще всего именно знания доменной области позволяет ML-инженером создать новый признак из нелинейной комбинации имеющихся, чтобы увеличить обобщающую способность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a14c93-ed9f-4d33-9ca3-064ef3d5ef8a",
   "metadata": {},
   "source": [
    "### 8. Как следует преобразовывать категориальные признаки, чтобы избежать путаницы алгоритма обучения, особенно когда порядок значений признака не важен?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf660c4-65a1-41e7-8196-4c70da0f106d",
   "metadata": {},
   "source": [
    "Необходимо закодировать такой признак и лучше в числовой формат. Например One-hot encoding может, расширив признаковое пространство, создать n-1 новый столбец, в каждом из которых появится отдельное значение признака и при его совпадении с образцом в ячейке будет 1, а иначе 0. Есть еще Label Encoding (похожа на ранги и в этом её минус), Target Encoding и другие. По умолчанию моделям ML тяжело работать с категориальными значениями и их нужно переводить в числовые, но такая библиотека как CatBoost способна самостоятельно обрабатывать категориальные признаки - это её особенность среди градиентных бустингов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdf7fa-b34c-4de7-8877-de070f616c15",
   "metadata": {},
   "source": [
    "### 9. Что такое стандартизация данных?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac1d49-218f-4395-b6cd-37c1004b700e",
   "metadata": {},
   "source": [
    "Чтобы слишком большие значения признаков или слишком маленькие (по масштабу) могли влиять на модель  их нужно загнать в рами диапозона [0, 1], так что среднее значение новых значений признаков станет 0, а средне квадратичное отклонение 1. Стандартизация увеличивает скорость работы некоторых алгоритмов. Проводится с помощью (X_i - X_сред) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2f34f-d545-4e83-a4f3-2667a69dad09",
   "metadata": {},
   "source": [
    "### 10. Объясните, зачем нужны три набора данных: обучающий, контрольный и тестовый."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b4eb3-112b-438d-b523-1eb4874bbeec",
   "metadata": {},
   "source": [
    "На тренировочном наборе модель обучается находить закономерности и важные зависимости в данных, на валидационной модель настраивает свои гиперпараметры (особенно хорошо при кросс-валидации), а на тестовой проверяется качество обученной модели на метриках."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb081d31-39e6-461c-8cb1-510b97bb8619",
   "metadata": {},
   "source": [
    "### 11. Что такое поиск по сетке, и как он используется для настройки гиперпараметров алгоритма?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357cd37e-87f8-443c-9de7-bcae5dc25070",
   "metadata": {},
   "source": [
    "GridSearchCV (в Scikit-Learn) - это подход для подбора гиперпараметров, который среди всех возможных комбинаций значений гиперпараметров, указанных инженером, выбирает ту, которая дает наилучший результат на метрике. Этот метод очень неэффективен на больших размерах данных или на большой комбинации значений признаков - очень затратен по времени. На практике все сейчас используют Optuna или Hyperopt для подбора гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12772843-1c01-494b-9081-c951860a4e79",
   "metadata": {},
   "source": [
    "### 12. Каковы основные компоненты нейронной сети, и как они взаимодействуют друг с другом?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e874cb-3f23-430b-b80e-5fc37be5ce6b",
   "metadata": {},
   "source": [
    "В нейрон поступает скалярное произведение выхода с нейронов предыдущего слоя на соответствующие им веса и добавляется сдвиг (bias). Затем в нем происходит нелинейная их трансформация с помощью функции активации и результат подаётся следующий слоям. Основная цель - подобрать оптимальные веса нейронной сети чтобы минимизировать функцию потерь. Данной минимизацией занимается оптимизатор (например Adam). Для обновления значения весов используется алгоритм обратного распространения ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb44055-fadf-4773-9c40-d44af539fc79",
   "metadata": {},
   "source": [
    "### 13. Как работает операция свертки, и какие гиперпараметры у нее есть?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83213bc0-1808-4059-a018-7e880f5dd221",
   "metadata": {},
   "source": [
    "Высчитывается скалярное произведение ядра свертки со схожим размером части изображения. Данное значение заносится в качестве значения пикселя нового изображения (карта признаков), что позволяет уменьшить количество весов для подбора, а каждый сверточный слой определяет разные объекты в данных вроде колес, дверей или шляп, а каждое ядро свертки отвечает за нахождение особенностей вроде линий, округлостей или др.\n",
    "\n",
    "Гиперпараметрами являются размер ядра свертки, количество ядер, размер шага свертки, размер паддинга (для сохранениях исходной размерности предыдущего слоя сети в следующем)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f0d39-e809-4c4d-b1fe-6004e0e229b4",
   "metadata": {},
   "source": [
    "### 14. Почему нелинейные компоненты важны в функции нейронной сети? Что произойдет, если их убрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd5faf-8295-4665-b797-f5027f5380b6",
   "metadata": {},
   "source": [
    "Модель не сможет улавливать нелинейные зависимости в данных. Линейная комбинация векторов так и останется линейной, что приведет к очень плохой обобщающей способности на сложных нелинейных зависимостях, по сути мы получим просто линейную регрессию. Даже если слоев в такой сети будет много их работа будет эквивалентна одному слою."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2080865-500b-4331-8fdc-c093139b65ef",
   "metadata": {},
   "source": [
    "### 15. Опишите проблему несбалансированных наборов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e383e62-8766-46fe-960c-03e3f3410af8",
   "metadata": {},
   "source": [
    "Один или несколько классов будут сильно выделяться, модель изучить много зависимостей такого класса и будет склонна предсказывать его чаще, но обобщающая способность предсказать представителей малого класса будет меньше. Хоть подход SMOTE для увеличения малого класса и предлагается на теории для балансировки, на практике его не используют и очень критикуют на Kaggle. Метрика Accuracy - плохой выбор на несбалансированных классах, поэтому лучше использовать precision или recall (еще подойдут метрики f1 и ROC AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270906c-133a-44d2-ad26-f6ac39a01fe7",
   "metadata": {},
   "source": [
    "### 16. Что такое штабелирование моделей (stacking) и как оно помогает улучшить общую производительность системы машинного обучения?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2bd98-1781-46b8-a3d6-bd4ac2834e87",
   "metadata": {},
   "source": [
    "Стекинг - это ансамбль, итоговое предсказание в котором делает мета-модель. Мета-модель (у меня мета-модель часто CatBoost) берет на вход предсказания нескольких моделей (мета-признаки), например линейных моделей и бустингов, и делает итоговое, менее переобученное, предсказание, учитывающее линейные и нелинейные зависимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2adb6-1f8c-4d43-8a97-86bbc051c776",
   "metadata": {},
   "source": [
    "### 17. Как можно адаптировать алгоритмы машинного обучения для работы с мультимодальными данными, например, с изображениями и текстом одновременно?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddf6c7-ec3e-4966-9927-702927a7a34e",
   "metadata": {},
   "source": [
    "Есть готовые подходы вроде ViT (vision transformers использует механизм внимания) и CLIP (одновременно обучается на картинках и тексте), которые сразу могут работать мультимодально (с картинками и текстом). Также можно обучать модели на тексте и картинках отдельно, а потом объединить все в одно признаковое пространство."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afbf10-3f1a-48ff-9823-083bfaa75a4f",
   "metadata": {},
   "source": [
    "### 18. В чем заключается суть переноса обучения (transfer learning), и как этот метод может быть полезен на практике?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22047b95-8285-453e-96be-afaab793c110",
   "metadata": {},
   "source": [
    "Чтобы не обучать модель с нуля на новых данных (которых мало) можно взять похожую модель, которая обучалась на больших данных и заморозив первые слои продолжить обучение последних слоев на своих (новых) данных чтобы теперь модель, предназначенная для решения задач на старых объектах, решала их для новых."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c2df59-c747-4787-850b-f74802cf9fa3",
   "metadata": {},
   "source": [
    "### 19. DBSCAN против k-средних: Сравните эти два алгоритма кластеризации, выделив их основные преимущества и недостатки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6035b5-a289-4f85-b0de-01e17ebd587e",
   "metadata": {},
   "source": [
    "В алгоритме k-средних один гиперпараметр, k (число кластеров), работает быстро. Начальное положение центроидов влияет на конечное, поэтому здесь результат порой зависит от случайности. k-средних очень чувствителен к выбросам. Оптимального метода выбора k нет. \n",
    "\n",
    "В DBSCAN есть уже целых два гиперпараметра (В HDBSCAN только n является гиперпараметром), также он хорошо работает если есть шумы в данных. В DBSCAN кластеры имеют произвольную форму, а в k-средних только форму гиперсферы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35dc54-cd68-4ee0-aae1-2ab8d21ac1ad",
   "metadata": {},
   "source": [
    "### 20. Какова цель сокращения размерности данных, и какие основные методы для этого используются на практике?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fea13-8225-41be-8d80-84760f7e0cc9",
   "metadata": {},
   "source": [
    "Уменьшая размерность признакового пространства, мы увеличиваем скорость обучения модели, снижаем вероятность переобучения. Основные алгоритмы - это PCA и UMAP.\n",
    "\n",
    "PCA - Метод главный компонент, который сохраняет лишь главные компоненты (самые информативные признаки), данные проецируются на эти признаки. UMAP - нужно для визуализации признакового пространства в 2D или 3D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a613c9e6-4a90-4055-9a9b-cefe2a689767",
   "metadata": {},
   "source": [
    "### 21. В чем разница между фильтрацией контента и совместной фильтрацией в рекомендательных системах?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b51c942-5fd5-4db5-b696-c2557acf5ef9",
   "metadata": {},
   "source": [
    "Фильтрация контента - это рекомендация, которая должна понравится пользователю, на основании истории потребляемого им контента. \n",
    "\n",
    "Совместная фильтрация - это рекомендация конкретному пользователю, на основании предпочтений других (похожих) пользователей, которые когда-то совпадали с конкретным пользователем по вкусам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7b9b4-a722-4f31-a81b-52f5400c7121",
   "metadata": {},
   "source": [
    "### 22. Объясните, что такое самообучение с учителем на примере вложений слов (word embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c410032-84bb-4665-a458-5c12820f8223",
   "metadata": {},
   "source": [
    "Самообучение с учителем - это метод обучения моделей на неразмеченных данных, когда  модель сама определяет для себя метки классов.\n",
    "\n",
    "Word embeddings - Это векторизация текста (в числовой формат). Самообучение в нем осуществляется так, что целевое слово подбирается, используя оставшиеся слова в предложении и контекст."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
